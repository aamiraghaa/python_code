from bs4 import BeautifulSoup
from urllib.request import urlopen
import re
#import requests

html_content = '''<!DOCTYPE html>
<html>
<head>
    <title>Example HTML Page</title>
</head>
<body>

<h1>Web Scraping Practice</h1>

<p>Here are some links:</p>

<ul>
    <li><a href="https://www.example.com/page1">Link to Page 1</a></li>
    <li><a href="https://www.example.com/page2">Link to Page 2</a></li>
    <li><a href="">Link to Search</a></li>
</ul>

<div>
    <p>Another set of links:</p>
    <ul>
        <li><a href="https://www.example.com/article1">Link to Article 1</a></li>
        <li><a href="https://www.example.com/article2">Link to Article 2</a></li>
        <li><a href="https://www.example.com/article3">Link to Article 3</a></li>
    </ul>
</div>

</body>
</html>
'''
soup = BeautifulSoup(html_content, 'html.parser')

#all_links = soup.find_all('a', string = re.compile('Search'))

all_links = soup.find_all('li', string = 'Link to Search')

if all_links:
  url = all_links[0].a.get('href')
  response = urlopen(url)
  print(response.read())

else:
  print('Something went wrong')




'''
from bs4 import BeautifulSoup
import requests
import re

url = ''
response = requests.get(url)

soup = BeautifulSoup(response.text, 'html.parser')
links = soup.find_all('td', string = re.compile('2024-01-19 10:45'))


if links:
    href = links[0].find_previous('a').get('href')
    print("CSV file href:", href)
else:
    print("No matching date found.")

if links:
    file_url = links['href']
    file_response = requests.get(file_url)
    if file_response.status_code == 200:
        file_path = 'downloaded_file.csv'
'''
